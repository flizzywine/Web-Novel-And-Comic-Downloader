* 记录设计这个项目的思路与过程

一开始我只是想找一个别人做的下载器来用,
但是在找遍了火狐浏览器插件, 油猴插件之后, 我没找到合适的工具
其实小说下载器以及很多很多了, 看小说也很方便, 但是我要看的都是一些色情小说,
很难在正规APP里看到, 下载
只能去求助一些偏门网站, 这些网站为了盈利, 故意让看小说变得很麻烦, 从而增加点击量, 更不用说铺天盖地的广告了
而且我非常希望能收藏这些色情小说中的经典, 而不是记住一个网址, 我也记不住那么多网址

于是自己开始做, 用requests下载, 用beautifulSoup解析
但是我不会用beautifulSoup, 在GitHub上找了一个类似的项目, 还不到50行, 抄了使用bs的部分
中途遇到了点小问题
比如乱码, 要先encode一次, 再decode到utf-8
还有就是找不到正文 
这个问题不大, 我很快就做好了功能,我下载了昨晚熬夜看的色情小说
然后我想, 可以开源出来啊
于是写文档, 做接口, 我还做了命令行和GUI两个版本
学着用了下argparse, 中途遇到点问题, 如何传入数组, 还有default只对optinal参数起作用

但是最大的问题在于我过早的做了接口
我的接口需要五个参数, 开始URL, 结束URL, title_selector , body_selector, out_file
编码的工作量就不必说了, 我必须到处写处理参数的代码, 最烦的是用起来
我下了几个不同网站的小说, 用的麻烦死了, 
而且遇到了几个奇葩的URL规律, 导致原来那个download基本作废, 
我不得不手撸一个download2出来, 也懒得搞什么传入参数的把戏, 直接把数据硬编码了
然后在下载的过程中又遇到了下载到一半会停的问题
还有重复下载, 结果后面的文件覆盖了之前的小说, 
或者重新下载, 结果内容重复了, 
在不同网站间切换, 我还得时刻注意配置, 

我很烦, 于是做了两个改动

第一: 改变URL规则, 一开始是有一个start_url, end_url从start到end
后来我改成类正则的表达方法 [100-200]用括号来批量处理, 简单多了, 真的, 
看起来差不多,其实在代码中, 一个变量比两个变量描述问题要容易很多

第二:自动配置
比如文件名, 我之前就默认为text.txt, 除非用户自己配置, 实际上我懒得要命, 根本不可能自己去配置文件名,
因为万一程序有问题, 这个时间就浪费了, 所以我就让程序自己找文本的title, 自动命名了

还有比如正文, 我一开始的打算也是用户自己输, 因为不可能全一样, 有的是.content, 有的是#content 
有的是.booktext,根本不可能一样
后来我麻烦死了, 于是写了个函数, 让程序自己找, 有跟content, context长的像的, 就直接默认掉
title也类似, 如果有h1,就用h1, 不然就找title标签

现在又遇到麻烦, 一个很短的小说, 要用很多时间来下载, 还有就是下载到一半会莫名停掉,
我接下来会考虑怎么处理一下这个问题

还有我发现, 对于程序员来说, 命令行比GUI快的多了, 必须等命令行先稳定了, 再考虑GUI的问题.
天下武功, 唯快不破, 测试一定要快, 每次迭代, 一定要快, 不然时间其实都浪费了, 

是时候认真学学git了, 不能再靠justtest过日子了, 学会git是不是, 那举手投足, 都是高手风范了

我敢不敢 , 是时候认真用git branch来处理一波问题了
merge 发生了什么

git checkout 主要是移动, -b是创建加移动
git brnach 主要是管理, 没有参数就是list, 有参数就是新建, -d就是删除

能不能试试分治法, 下载, 还有, 是开新的进程呢, 还是多线程呢, 多线程其实效率不高
接下来学习使用git 然后用分治法加快一下程序下载速度 

git 的track到底是什么意思
upstream ahead behind 
